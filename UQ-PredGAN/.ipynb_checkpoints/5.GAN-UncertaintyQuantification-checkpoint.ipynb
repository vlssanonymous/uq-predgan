{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================\n",
    "### Code developed by: Vinicius Luiz Santos Silva\n",
    "\n",
    "### Contact: v.santos-silva19@imperial.ac.uk / viluiz@gmail.com\n",
    "=================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "import joblib\n",
    "import shutil\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "# Python path for running in parallel (conda env py3ml)\n",
    "pythonpath = '/home/viluiz/anaconda3/envs/py3ml/bin/python'\n",
    "assert os.path.exists(pythonpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Load data and GAN model\n",
    "# -----------------------------------------\n",
    "\n",
    "# Mesh size\n",
    "nl = 10\n",
    "nc = 10\n",
    "\n",
    "#Load PCA and Scaler\n",
    "pca_compress = joblib.load(\"pca_compress_15.pkl\") \n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Train data\n",
    "X_train_compressed = np.loadtxt('X_train_pca.csv', delimiter=',') \n",
    "X_train_1D = np.loadtxt('X_train_1D.csv', delimiter=',') \n",
    "times  = np.loadtxt('times.csv', delimiter=',') \n",
    "R0s_train  = np.loadtxt('R0s.csv', delimiter=',') \n",
    "with open('groups.txt') as f:\n",
    "    groups = [g.strip() for g in f.readlines()]\n",
    "\n",
    "# Test data\n",
    "X_test_compressed = np.loadtxt('X_test_pca.csv', delimiter=',') \n",
    "X_test_1D = np.loadtxt('X_test_1D.csv', delimiter=',') \n",
    "R0s_test  = np.loadtxt('R0s_test.csv', delimiter=',') \n",
    "\n",
    "# Test uq data\n",
    "X_testuq_compressed = np.loadtxt('X_testuq_pca.csv', delimiter=',') \n",
    "X_testuq_1D = np.loadtxt('X_testuq_1D.csv', delimiter=',') \n",
    "R0s_testuq  = np.loadtxt('R0s_testuq.csv', delimiter=',') \n",
    "\n",
    "# GAN model\n",
    "#generator, discriminator = load_model('gan-tfex-DCGAN-5kernel.h5').layers\n",
    "#latent_size = 100 # size of the latent space (input of the generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Prepare data\n",
    "# -----------------------------------------\n",
    "\n",
    "pca_size = X_test_compressed.shape[1] # number of POD coeffients\n",
    "\n",
    "X_train_R0s = R0s_train.repeat(len(times), axis=0) \n",
    "X_test_R0s = R0s_test.repeat(len(times), axis=0)\n",
    "X_testuq_R0s = R0s_testuq.repeat(len(times), axis=0)\n",
    "\n",
    "X_train_compressedplus = np.concatenate((X_train_compressed, X_train_R0s), axis=1) \n",
    "X_test_compressedplus = np.concatenate((X_test_compressed, X_test_R0s), axis=1) \n",
    "X_testuq_compressedplus = np.concatenate((X_testuq_compressed, X_testuq_R0s), axis=1) \n",
    "codings_size = X_test_compressedplus.shape[1] # number of POD coeffients + the number of model parameters\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_compressedplus)\n",
    "X_test_scaled = scaler.transform(X_test_compressedplus)\n",
    "X_testuq_scaled = scaler.transform(X_testuq_compressedplus)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=[20,4])\n",
    "ax[0].hist(X_train_scaled.flatten())\n",
    "ax[0].set_title('Train')\n",
    "ax[1].hist(X_test_scaled.flatten())\n",
    "ax[1].set_title('Test')\n",
    "ax[2].hist(X_testuq_scaled.flatten())\n",
    "ax[2].set_title('Testuq')\n",
    "\n",
    "# Concatenate successive time steps  \n",
    "def concat_timesteps(X_train, ntimes, step, times):\n",
    "    X_train_concat = []\n",
    "    for j in range(len(X_train)//len(times)):\n",
    "        for i in range(j*len(times), j*len(times)+(len(times)-ntimes*step)):\n",
    "            X_train_concat.append(X_train[i:i+ntimes*step:step])\n",
    "    return np.array(X_train_concat)\n",
    "\n",
    "ntimes = 10 # Consecutive times for the GAN\n",
    "step = 2 # step between times\n",
    "\n",
    "X_train_concat = concat_timesteps(X_train_scaled, ntimes, step, times)\n",
    "X_train_concat_flatten = X_train_concat.reshape(X_train_concat.shape[0], codings_size*ntimes )\n",
    "\n",
    "X_test_concat = concat_timesteps(X_test_scaled, ntimes, step, times)\n",
    "X_test_concat_flatten = X_test_concat.reshape(X_test_concat.shape[0], codings_size*ntimes )\n",
    "\n",
    "X_testuq_concat = concat_timesteps(X_testuq_scaled, ntimes, step, times)\n",
    "X_testuq_concat_flatten = X_testuq_concat.reshape(X_testuq_concat.shape[0], codings_size*ntimes )\n",
    "\n",
    "fig, ax1 = plt.subplots(1,3, figsize=[20,4])\n",
    "print(X_train_concat.shape)\n",
    "ax1[0].imshow(X_train_concat[10000, :, :])\n",
    "print(X_test_concat.shape)\n",
    "ax1[1].imshow(X_test_concat[10000, :, :])\n",
    "print(X_testuq_concat.shape)\n",
    "ax1[2].imshow(X_testuq_concat[10000, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=[12,4])\n",
    "ax[0].hist(R0s_testuq[:,0])\n",
    "ax[0].set_title('R0 Home')\n",
    "ax[1].hist(R0s_testuq[:,1])\n",
    "ax[1].set_title('R0 Mobile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate observed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Generate observed data\n",
    "# -----------------------------------------\n",
    "\n",
    "run_obs = 2 # from the test dataset\n",
    "lag = 173 # starting point (in time steps)\n",
    "length = 250 # length + (ntimes-1) -> len of X_obs (in forward steps = 2 time steps) \n",
    "seed = 0\n",
    "noise = 0.00\n",
    "\n",
    "# Times of X_obs to be considered for data assimilation\n",
    "obs_times = list(map(int,map(round,np.arange(0,length+(ntimes-1)-120,21.6))))\n",
    "\n",
    "\n",
    "# grid points: used to populate the obs_points\n",
    "#[[group, line, column], \n",
    "# [group, line, column], \n",
    "# ...                 ]\n",
    "grid_points = [[2,0,4],[6,0,4],[3,0,4],[7,0,4],\n",
    "               [2,9,4],[6,9,4],[3,9,4],[7,9,4],\n",
    "               [2,4,4],[6,4,4],[3,4,4],[7,4,4],\n",
    "               [2,4,0],[6,4,0],[3,4,0],[7,4,0],\n",
    "               [2,4,9],[6,4,9],[3,4,9],[7,4,9],\n",
    "               #[0,0,4],[1,0,4],[2,0,4],[3,0,4],[4,0,4],[5,0,4],[6,0,4],[7,0,4],\n",
    "               #[0,9,4],[1,9,4],[2,9,4],[3,9,4],[4,9,4],[5,9,4],[6,9,4],[7,9,4],\n",
    "               #[0,4,4],[1,4,4],[2,4,4],[3,4,4],[4,4,4],[5,4,4],[6,4,4],[7,4,4],\n",
    "               #[0,4,0],[1,4,0],[2,4,0],[3,4,0],[4,4,0],[5,4,0],[6,4,0],[7,4,0],\n",
    "               #[0,4,9],[1,4,9],[2,4,9],[3,4,9],[4,4,9],[5,4,9],[6,4,9],[7,4,9],\n",
    "               ]\n",
    "\n",
    "def obs_data(run_obs, lag, length, seed, noise, obs_times, grid_points, verbose=0):\n",
    "\n",
    "    nobs = len(times)*run_obs + lag\n",
    "\n",
    "    # Get the observed data\n",
    "    X_obs = X_test_1D[nobs:nobs+((ntimes-1)+length)*step:step,:].reshape(-1,len(groups),nl,nc)\n",
    "    R0s_obs = R0s_test[run_obs]\n",
    "\n",
    "    # Add noise\n",
    "    np.random.seed(seed)\n",
    "    X_obs = X_obs + np.random.standard_normal(X_obs.shape)*noise*X_obs\n",
    "\n",
    "    # Print values\n",
    "    if verbose>0: \n",
    "        print('X_obs.shape', X_obs.shape)\n",
    "        print('R0s_obs', R0s_obs)\n",
    "\n",
    "    # obs_points:\n",
    "    #[[time, group, line, column], \n",
    "    # [time, group, line, column], \n",
    "    # ...                       ]\n",
    "    obs_points = []\n",
    "    for p in grid_points:\n",
    "        for t in obs_times:\n",
    "            obs_points.append([t]+p)\n",
    "    obs_points = np.array(obs_points)\n",
    "    if verbose>0:\n",
    "        print('obs_points.shape: ', obs_points.shape)\n",
    "    \n",
    "    return X_obs, R0s_obs, obs_points\n",
    "\n",
    "X_obs, R0s_obs, obs_points = obs_data(run_obs, lag, length, seed, noise, obs_times, grid_points, verbose=1)\n",
    "\n",
    "fig, X_ax = plt.subplots(4,2, figsize=[20,15])\n",
    "for i, group in enumerate(groups):\n",
    "    if [i, 0, 4] in grid_points:\n",
    "        X_ax.flatten()[i].plot(np.array(obs_times)*8000/86400, X_obs[obs_times][:, i, 0, 4], 'o', markevery=1, fillstyle='none', markersize = 12, label='Observed data')\n",
    "    else:\n",
    "        X_ax.flatten()[i].plot([],[])\n",
    "    X_ax.flatten()[i].plot(np.array(range(len(X_obs)))*8000/86400, X_obs[:][:, i, 0, 4], '-', markevery=1, fillstyle='none', markersize = 12, label='Observed data')        \n",
    "    X_ax.flatten()[i].set_title(group)\n",
    "    X_ax.flatten()[i].set_xlabel('Time (days)')\n",
    "    X_ax.flatten()[i].set_ylabel('Number of People')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run uncertainty quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nparalel = 40\n",
    "processes = []\n",
    "dirnames = []\n",
    "logfile = []\n",
    "\n",
    "n_testuq = int(len(X_testuq_concat)/(len(times)- ntimes*step))\n",
    "\n",
    "pyfile = 'da-predgan.py'\n",
    "rundir = 'runuq_1/'\n",
    "if os.path.exists(rundir):\n",
    "    print('\\n*** WARNING: Directory already exists: ./' + rundir)\n",
    "    print('\\n*** WARNING: All data assimilations will be considered finished!')\n",
    "    print('\\nContinuing execution!')\n",
    "else:\n",
    "    os.mkdir(rundir)\n",
    "\n",
    "    j = 0\n",
    "    for i in range(n_testuq):\n",
    "\n",
    "        # Create folder and copy files\n",
    "        dirnames.append( rundir+'testuq'+str(i)+'seed'+str(i)+'/')\n",
    "        if os.path.exists(dirnames[-1]):\n",
    "            print('directory already exists: ' + os.path.abspath(dirnames[-1]))\n",
    "            continue \n",
    "        #print('Creating folder '+dirnames[-1]+' and copying files... ', end='')\n",
    "        os.mkdir(dirnames[-1])\n",
    "        shutil.copy(pyfile, dirnames[-1])\n",
    "        #print('Done!')        \n",
    "\n",
    "        # Generate observed data (seed = i)\n",
    "        X_obs, R0s_obs, obs_points = obs_data(run_obs, lag, length, i, 0.05, obs_times, grid_points)\n",
    "\n",
    "        # Initial condition (run_ini = i)\n",
    "        n = (len(times)-ntimes*step)*i + lag\n",
    "        forward_steps = length\n",
    "        initial_coding = X_testuq_concat[n]\n",
    "\n",
    "        #save inputs\n",
    "        input_data = (initial_coding, X_obs, obs_points, forward_steps) \n",
    "        joblib.dump(input_data, dirnames[-1]+'input_data.pkl') \n",
    "\n",
    "        # Check for finished jobs and write output to file\n",
    "        while not len(processes) < nparalel:\n",
    "            time.sleep(60)\n",
    "            for i, p in enumerate(processes):\n",
    "                if p.poll() != None:\n",
    "                    j += 1\n",
    "                    print('Run '+str(j)+': '+dirnames[i]+' finished! status:' + str(p.poll()))\n",
    "                    processes.pop(i)\n",
    "                    dirnames.pop(i)\n",
    "                    logfile[i].close()\n",
    "                    break\n",
    "        # Run case \n",
    "        logfile.append(open(dirnames[-1] + 'run.log','w'))\n",
    "        processes.append(subprocess.Popen([pythonpath, pyfile], \n",
    "                                          cwd=dirnames[-1], \n",
    "                                          stdout=logfile[-1], \n",
    "                                          stderr=logfile[-1],\n",
    "                                          close_fds=True))\n",
    "        print(dirnames[-1]+' running...')       \n",
    "\n",
    "\n",
    "    #Check for finished jobs and write output to file\n",
    "    while len(processes) > 0:\n",
    "        time.sleep(60)\n",
    "        for i, p in enumerate(processes):\n",
    "            if p.poll() != None:\n",
    "                j += 1\n",
    "                print('Run '+str(j)+': '+dirnames[i]+' finished! status:' + str(p.poll()))\n",
    "                processes.pop(i)\n",
    "                dirnames.pop(i)\n",
    "                logfile[i].close()\n",
    "                break\n",
    "    print('Finished!')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read output files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = 0\n",
    "f = 0\n",
    "list_output_data = []\n",
    "runtime = []\n",
    "final_loss = []\n",
    "iteration = []\n",
    "runs = sorted(glob.glob(rundir+'*'))\n",
    "for run in runs:\n",
    "    if os.path.exists(run+'/output_data.pkl'):\n",
    "        f += 1\n",
    "        with open(run+'/run.log') as file:\n",
    "            lines = file.readlines()\n",
    "            c = 0\n",
    "            for l, line in enumerate(reversed(lines)):\n",
    "                if line.strip() == '':\n",
    "                    continue\n",
    "                elif 'loss:' in line:\n",
    "                    final_loss.append(float(line.split()[-1].replace('s','')))\n",
    "                    c+=1\n",
    "                elif 'Iterations:' in line:\n",
    "                    iteration.append(int(line.split()[-1].replace('s','')))    \n",
    "                    c+=1\n",
    "                elif 'Runtime:' in line:\n",
    "                    runtime.append(int(line.split()[-1].replace('s','')))\n",
    "                    c+=1\n",
    "                elif l>10:    \n",
    "                    break\n",
    "            if c<3:\n",
    "                print(run+'/run.log ERROR!')\n",
    "                break\n",
    "        list_output_data.append(joblib.load(run+'/output_data.pkl'))                     \n",
    "        print('{:30s}'.format(run+':')+\n",
    "              '{:15s}'.format('runtime='+str(runtime[-1]))+\n",
    "              '{:15s}'.format('iterations='+str(iteration[-1]))+\n",
    "              '{:10s}'.format('loss='+str(final_loss[-1])))            \n",
    "    else:\n",
    "        r += 1\n",
    "        print(run+'/output_data.pkl not found!')\n",
    "list_output_data = np.array(list_output_data)    \n",
    "print('\\nFinished: ', f)\n",
    "print('Running: ', r)\n",
    "\n",
    "# Plot forward and backward march   \n",
    "mpl.rcParams.update({'font.size': 18})\n",
    "mpl.rc('xtick', labelsize=18) \n",
    "mpl.rc('ytick', labelsize=18) \n",
    "mpl.rc('axes', labelsize=18)\n",
    "fig, ax = plt.subplots(1,1, figsize=[6,4])\n",
    "ax.hist(final_loss, bins=20)\n",
    "ax.set_title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_output_data = list_output_data[np.array(final_loss) < 0.02]\n",
    "print(list_output_data.shape, '->', updated_output_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X_predict, nx, ny, obs_times=[], X_obs=[], grid_points=[], R0s_obs=[], R0_ax='', X_ax='', label='', color='b'):\n",
    "    X_generated = scaler.inverse_transform(X_predict)\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(len(X_predict), len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    \n",
    "    # Plot R\n",
    "    xp = len(R0_generated)\n",
    "    if R0_ax:\n",
    "        R0_ax.plot(np.linspace(0,(xp-1)*8000/86400,xp), R0_generated[:,0], 'b', label='Home '+label)\n",
    "        R0_ax.plot(np.linspace(0,(xp-1)*8000/86400,xp), R0_generated[:,1], 'r', label='Mobile '+label)\n",
    "        if len(R0s_obs):\n",
    "            R0_ax.plot(np.linspace(0,(xp-1)*8000/86400,xp), [R0s_obs[0]]*len(R0_generated), 'bo', markevery=2, fillstyle='none', markersize = 10, label='Home truth')\n",
    "            R0_ax.plot(np.linspace(0,(xp-1)*8000/86400,xp), [R0s_obs[1]]*len(R0_generated), 'ro', markevery=2, fillstyle='none', markersize = 10, label='Mobile truth')    \n",
    "        if len(label):\n",
    "        #    R0_ax.legend()\n",
    "            R0_ax.set_xlabel('Time (days)')\n",
    "            R0_ax.set_ylabel('Reproduction number')\n",
    "        #plt.tight_layout()\n",
    "        #plt.grid()\n",
    "        #plt.show()\n",
    "\n",
    "    \n",
    "    # Plot groups \n",
    "    if len(X_ax): \n",
    "        for i, group in enumerate(groups):\n",
    "            X_ax.flatten()[i].plot(np.linspace(0,(xp-1)*8000/86400,xp), X_generated[:,i, nx, ny], color=color, label=label)\n",
    "            if len(X_obs):\n",
    "                if [i, nx, ny] in grid_points:\n",
    "                    X_ax.flatten()[i].plot(np.array(obs_times)*8000/86400, X_obs[:, i, nx, ny], 'ro', markevery=1, fillstyle='full', markersize = 12, label='Observed data')\n",
    "                else:\n",
    "                    X_ax.flatten()[i].plot([],[])\n",
    "            X_ax.flatten()[i].set_title(group)\n",
    "            if len(label):\n",
    "            #    X_ax.flatten()[i].legend()\n",
    "                X_ax.flatten()[i].set_xlabel('Time (days)')\n",
    "                X_ax.flatten()[i].set_ylabel('Number of People')\n",
    "            #X_ax.flatten()[i].set_xlim(8,12)    \n",
    "        #plt.tight_layout()\n",
    "        #plt.grid()\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forward and backward march   \n",
    "fig, R0_ax = plt.subplots(1,1, figsize=[8,4])\n",
    "fig, X_ax = plt.subplots(2,4, figsize=[20,10])\n",
    "\n",
    "for output_data in list_output_data:\n",
    "    plot_data(output_data[0], 0, 4, obs_times, X_obs[obs_times], grid_points, R0s_obs, R0_ax=R0_ax, X_ax=X_ax, label='')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forward and backward march   \n",
    "fig, R0_ax = plt.subplots(1,1, figsize=[8,4])\n",
    "fig, X_ax = plt.subplots(2,4, figsize=[20,10])\n",
    "\n",
    "for output_data in updated_output_data:\n",
    "    plot_data(output_data[1], 0, 4, obs_times, X_obs[obs_times], grid_points, R0s_obs, R0_ax=R0_ax, X_ax=X_ax, label='')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forward and backward march   \n",
    "fig, X_ax = plt.subplots(2,4, figsize=[20,10])\n",
    "\n",
    "for output_data in list_output_data:\n",
    "    plot_data(output_data[0], 0, 4, obs_times=[], X_obs=[], grid_points=[], R0s_obs=[], R0_ax='', X_ax=X_ax, label='',color='gray')\n",
    "\n",
    "for output_data in updated_output_data:\n",
    "    plot_data(output_data[1], 0, 4, obs_times=[], X_obs=[], grid_points=[], R0s_obs=[], R0_ax='', X_ax=X_ax, label='', color='b')\n",
    "    \n",
    "X_mean = np.zeros((259, 8, 10, 10))\n",
    "for output_data in updated_output_data:\n",
    "    \n",
    "    X_generated = scaler.inverse_transform(output_data[1])\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    n_ts = len(X_generated)\n",
    "    X_mean += X_generated\n",
    "X_mean /= len(updated_output_data)  \n",
    "     \n",
    "# Plot groups \n",
    "if len(X_ax): \n",
    "    for i, group in enumerate(groups):\n",
    "        X_ax.flatten()[i].plot(np.linspace(0,(n_ts-1)*8000/86400,n_ts), X_mean[:,i, 0, 4], 'k-', label='label', zorder=3)\n",
    "        if len(X_obs):\n",
    "            if [i, 0, 4] in grid_points:\n",
    "                X_ax.flatten()[i].plot(np.array(obs_times)*8000/86400, X_obs[obs_times][:, i, 0, 4], 'ro', markevery=1, fillstyle='full', markersize = 8, label='Observed data',zorder=3)\n",
    "            else:\n",
    "                X_ax.flatten()[i].plot([],[])\n",
    "        X_ax.flatten()[i].set_title(group)\n",
    "        #    X_ax.flatten()[i].legend()\n",
    "        X_ax.flatten()[i].set_xlabel('Time (days)')\n",
    "        X_ax.flatten()[i].set_ylabel('Number of People')\n",
    "        #X_ax.flatten()[i].set_xlim(8,12)    \n",
    "    #plt.tight_layout()\n",
    "    #plt.grid()\n",
    "    #plt.show()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the iterations where there are observed data\n",
    "obs_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 18})\n",
    "mpl.rc('xtick', labelsize=18) \n",
    "mpl.rc('ytick', labelsize=18) \n",
    "mpl.rc('axes', labelsize=18)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=[5,5])\n",
    "#for i, group in enumerate(groups):\n",
    "im = ax.imshow(X_mean[135,4,:,:], origin='lower')\n",
    "clb = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "clb.set_label(label='Number of people', size=22)\n",
    "ax.set_title(groups[4])\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=[5,5])\n",
    "#for i, group in enumerate(groups):\n",
    "im = ax.imshow(X_mean[130,4,:,:], origin='lower', vmin=0)\n",
    "clb = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "clb.set_label(label='Number of people', size=22)\n",
    "ax.set_title(groups[4])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 130\n",
    "R0_hist_prior = []\n",
    "for output_data in list_output_data[:,0]: \n",
    "    X_generated = scaler.inverse_transform(output_data)\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "\n",
    "    R0_hist_prior.append(R0_generated[time,:])\n",
    "R0_hist_prior = np.array(R0_hist_prior)\n",
    "\n",
    "R0_hist_post = []\n",
    "for output_data in updated_output_data[:,1]: \n",
    "    X_generated = scaler.inverse_transform(output_data)\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "\n",
    "    R0_hist_post.append(R0_generated[time,:])\n",
    "R0_hist_post = np.array(R0_hist_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 14})\n",
    "mpl.rc('xtick', labelsize=18) \n",
    "mpl.rc('ytick', labelsize=18) \n",
    "mpl.rc('axes', labelsize=18)\n",
    "\n",
    "#fig, R0_ax0 = plt.subplots(1,2, figsize=[12,4])\n",
    "fig, R0_ax0 = plt.subplots(1,1, figsize=[6,4])\n",
    "fig, R0_ax1 = plt.subplots(1,1, figsize=[6,4])\n",
    "R0_ax = [R0_ax0, R0_ax1]\n",
    "\n",
    "# Plot R0 histograms\n",
    "#xrange = (min(R0_hist.min(),R0s_obs[0],R0s_obs[1]),max(R0_hist.max(),R0s_obs[0],R0s_obs[1])) \n",
    "R0_ax[0].hist(R0_hist_prior[:,0], bins=20, density=True, label='prior', alpha=0.7)#, range=xrange)\n",
    "R0_ax[0].hist(R0_hist_post[:,0], bins=20, density=True, label='posterior', alpha=0.7)#, range=xrange)\n",
    "R0_ax[0].set_xlabel('R0 Home')\n",
    "R0_ax[1].hist(R0_hist_prior[:,1], bins=20, density=True, label='prior', alpha=0.7)#, range=xrange)\n",
    "R0_ax[1].hist(R0_hist_post[:,1], bins=20, density=True, label='posterior', alpha=0.7)#, range=xrange)\n",
    "R0_ax[1].set_xlabel('R0 Mobile')\n",
    "\n",
    "yrange = R0_ax[0].get_ybound()\n",
    "R0_ax[0].plot([R0s_obs[0]]*2,yrange, linewidth=3, label='Ground truth')\n",
    "R0_ax[0].set_ylim(yrange)\n",
    "yrange = R0_ax[1].get_ybound()\n",
    "R0_ax[1].plot([R0s_obs[1]]*2,yrange, linewidth=3, label='Ground truth')\n",
    "R0_ax[1].set_ylim(yrange)     \n",
    "\n",
    "R0_ax[0].legend()\n",
    "#plt.tight_layout()\n",
    "plt.show\n",
    "R0_ax[1].legend()\n",
    "#plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, R0_ax = plt.subplots(1,1, figsize=[6,6])\n",
    "\n",
    "R0_ax.scatter(R0_hist_prior[:,0],R0_hist_prior[:,1])\n",
    "R0_ax.scatter(R0_hist_post[:,0],R0_hist_post[:,1])\n",
    "R0_ax.scatter(R0s_obs[0],R0s_obs[1], s=200, marker='*', c='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R0e_hist_prior = []\n",
    "R0e_hist_post = []\n",
    "\n",
    "for output_data in list_output_data[:,0]: \n",
    "    X_generated = scaler.inverse_transform(output_data)\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    \n",
    "    aux_prior = 0\n",
    "    for time in range(130,131):#range(n_ts)\n",
    "        s = X_generated[time,0,:,:].sum()/(X_generated[time,0,:,:].sum()+X_generated[time,4,:,:].sum())\n",
    "        aux_prior += R0_generated[time,0]*s+R0_generated[time,1]*(1-s)\n",
    "        #R0e_hist_prior.append(R0_generated[time,0]*s+R0_generated[time,1]*(1-s))  \n",
    "    R0e_hist_prior.append(aux_prior)#/n_ts)\n",
    "        \n",
    "for output_data in updated_output_data[:,1]: \n",
    "    X_generated = scaler.inverse_transform(output_data)\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    \n",
    "    aux_post = 0\n",
    "    for time in range(130,131):#range(n_ts)\n",
    "        s = X_generated[time,0,:,:].sum()/(X_generated[time,0,:,:].sum()+X_generated[time,4,:,:].sum())\n",
    "        aux_post += R0_generated[time,0]*s+R0_generated[time,1]*(1-s)\n",
    "        #R0e_hist_post.append(R0_generated[time,0]*s+R0_generated[time,1]*(1-s))  \n",
    "    R0e_hist_post.append(aux_post)#/n_ts)\n",
    "    \n",
    "R0e_hist_prior = np.array(R0e_hist_prior)\n",
    "R0e_hist_post = np.array(R0e_hist_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 14})\n",
    "mpl.rc('xtick', labelsize=18) \n",
    "mpl.rc('ytick', labelsize=18) \n",
    "mpl.rc('axes', labelsize=18)\n",
    "\n",
    "fig, R0_ax = plt.subplots(1,1, figsize=[6,4])\n",
    "\n",
    "# Plot R0 histograms\n",
    "R0_ax.hist(R0e_hist_prior, density=True, label='prior', alpha=0.7)#, bins=20)\n",
    "R0_ax.hist(R0e_hist_post, density=True, label='posterior', alpha=0.7)#, bins=20)\n",
    "R0_ax.set_xlabel('Effective R0')\n",
    "\n",
    "yrange = (R0_ax.get_ybound())\n",
    "aux_obs = 0\n",
    "for time in range(130,131):#range(n_ts)\n",
    "    s_obs = X_obs[time,0,:,:].sum()/(X_obs[time,0,:,:].sum()+X_obs[time,4,:,:].sum())\n",
    "    aux_obs += R0s_obs[0]*s_obs+R0s_obs[1]*(1-s_obs)\n",
    "R0e_obs = aux_obs#/n_ts\n",
    "\n",
    "R0_ax.plot([R0e_obs]*2,yrange, linewidth=3, label='Ground truth')\n",
    "R0_ax.set_ylim(yrange)    \n",
    "\n",
    "R0_ax.set_xlim(0,20) \n",
    "R0_ax.legend()\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, R0_ax = plt.subplots(1,2, figsize=[12,4])\n",
    "\n",
    "# Plot R0 histograms\n",
    "R0_ax[0].hist(R0e_hist_prior, density=True, label='prior', alpha=0.7)\n",
    "R0_ax[0].set_xlabel('Effective R0')\n",
    "yrange = (R0_ax[0].get_ybound())\n",
    "s_obs = X_obs[time,0,:,:].sum()/(X_obs[time,0,:,:].sum()+X_obs[time,4,:,:].sum())\n",
    "R0_ax[0].plot([R0s_obs[0]*s_obs+R0s_obs[1]*(1-s_obs)]*2,yrange, linewidth=3, label='Ground truth')\n",
    "R0_ax[0].set_ylim(yrange)  \n",
    "R0_ax[0].set_xlim(0,20) \n",
    "R0_ax[0].legend()\n",
    "\n",
    "R0_ax[1].hist(R0e_hist_post, density=True, label='posterior', alpha=0.7)\n",
    "R0_ax[1].set_xlabel('Effective R0')\n",
    "yrange = (R0_ax[1].get_ybound())\n",
    "s_obs = X_obs[time,0,:,:].sum()/(X_obs[time,0,:,:].sum()+X_obs[time,4,:,:].sum())\n",
    "R0_ax[1].plot([R0s_obs[0]*s_obs+R0s_obs[1]*(1-s_obs)]*2,yrange, linewidth=3, label='Ground truth')\n",
    "R0_ax[1].set_ylim(yrange)  \n",
    "R0_ax[1].set_xlim(0,20) \n",
    "R0_ax[1].legend()\n",
    "  \n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 130\n",
    "X_hist_prior = []\n",
    "for output_data in list_output_data[:,0]: \n",
    "    X_generated = scaler.inverse_transform(output_data)\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "\n",
    "    X_hist_prior.append(X_generated[time,:, 0, 4].reshape(len(groups),-1).sum(axis=1))  \n",
    "X_hist_prior = np.array(X_hist_prior)\n",
    "\n",
    "X_hist_post = []\n",
    "for output_data in updated_output_data[:,1]: \n",
    "    X_generated = scaler.inverse_transform(output_data)\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "\n",
    "    X_hist_post.append(X_generated[time,:, 0, 4].reshape(len(groups),-1).sum(axis=1))  \n",
    "X_hist_post = np.array(X_hist_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forward and backward march   \n",
    "mpl.rcParams.update({'font.size': 16})\n",
    "mpl.rc('xtick', labelsize=22) \n",
    "mpl.rc('ytick', labelsize=22) \n",
    "mpl.rc('axes', labelsize=22)\n",
    "mpl.rc('axes', titlesize=22)\n",
    "\n",
    "fig, X_ax = plt.subplots(2,4, figsize=[20,10])\n",
    "# Plot groups histograms\n",
    "for i, group in enumerate(groups):\n",
    "        #xrange = (X_hist[:,:4].min(),X_hist[:,:4].max()) if brange else None\n",
    "        X_ax.flatten()[i].hist(X_hist_prior[:,i], density=True, label='prior',alpha=0.7)\n",
    "        X_ax.flatten()[i].hist(X_hist_post[:,i], density=True, label='posterior',alpha=0.7)\n",
    "        X_ax.flatten()[i].set_xlabel('Number of people')\n",
    "        X_ax.flatten()[i].ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "\n",
    "        if i in np.array(grid_points)[:,0] and time in obs_times:\n",
    "            yrange = X_ax.flatten()[i].get_ybound()\n",
    "            X_ax.flatten()[i].plot([X_obs[time, i, 0, 4].sum()]*2,yrange, linewidth=3, label='Obs data')\n",
    "            X_ax.flatten()[i].set_ylim(yrange)      \n",
    "        X_ax.flatten()[i].set_title(group)\n",
    "        X_ax.flatten()[i].legend()     \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the whole population with the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compartments = ['Susceptible','Exposed','Infecitous','Recovered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, X_ax = plt.subplots(1,4, figsize=[20,5])\n",
    "\n",
    "for output_data in list_output_data:\n",
    "    \n",
    "    X_generated = scaler.inverse_transform(output_data[0])\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    n_ts = len(X_generated)\n",
    "    \n",
    "    # Plot groups \n",
    "    if len(X_ax): \n",
    "        for i, group in enumerate(compartments):\n",
    "            X_ax.flatten()[i].plot(np.linspace(0,(n_ts-1)*8000/86400,n_ts), \n",
    "                                   X_generated[:,[i,i+4], :, :].reshape(len(X_generated),-1).sum(axis=1), \n",
    "                                   'b-', \n",
    "                                   label='Priors')\n",
    "                    \n",
    "        \n",
    "for i, group in enumerate(compartments):\n",
    "    if i in np.array(grid_points)[:,0]:\n",
    "        X_ax.flatten()[i].plot(np.array(obs_times)*8000/86400, \n",
    "                              X_obs[obs_times][:, [i,i+4], :, :].reshape(len(obs_times),-1).sum(axis=1), \n",
    "                              'ro', markevery=1, \n",
    "                              fillstyle='full', \n",
    "                              markersize = 10, \n",
    "                              label='Ground truth')\n",
    "#         X_ax.flatten()[i].errorbar(np.array(obs_times)*8000/86400, \n",
    "#                                    X_obs[obs_times][:, [i,i+4], :, :].reshape(len(obs_times),-1).sum(axis=1),\n",
    "#                                    yerr=3*0.05*X_obs[obs_times][:, [i,i+4], :, :].reshape(len(obs_times),-1).sum(axis=1),\n",
    "#                                    fmt='or',\n",
    "#                                    markersize = 8, \n",
    "#                                    elinewidth=4,\n",
    "#                                    #capsize = 10,\n",
    "#                                    #barsabove=True,\n",
    "#                                    zorder=3)\n",
    "        \n",
    "    X_ax.flatten()[i].set_title(group)\n",
    "    #X_ax.flatten()[i].legend()\n",
    "    X_ax.flatten()[i].set_xlabel('Time (days)')\n",
    "    X_ax.flatten()[i].set_ylabel('Number of People')\n",
    "    #X_ax.flatten()[0].set_ylim(top=8000)\n",
    "    \n",
    "X_mean = np.zeros((259, 8, 10, 10))\n",
    "for output_data in list_output_data:\n",
    "    \n",
    "    X_generated = scaler.inverse_transform(output_data[0])\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    n_ts = len(X_generated)\n",
    "    X_mean += X_generated\n",
    "X_mean /= len(list_output_data)  \n",
    "\n",
    "# Plot groups \n",
    "if len(X_ax): \n",
    "    for i, group in enumerate(compartments):\n",
    "        X_ax.flatten()[i].plot(np.linspace(0,(n_ts-1)*8000/86400,n_ts), \n",
    "                               X_mean[:,[i,i+4], :, :].reshape(len(X_generated),-1).sum(axis=1), \n",
    "                               'k-', \n",
    "                               label='Priors')\n",
    "        \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, X_ax = plt.subplots(1,4, figsize=[20,5])\n",
    "\n",
    "for output_data in updated_output_data:\n",
    "    \n",
    "    X_generated = scaler.inverse_transform(output_data[1])\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    n_ts = len(X_generated)\n",
    "    \n",
    "    # Plot groups \n",
    "    if len(X_ax): \n",
    "        for i, group in enumerate(compartments):\n",
    "            X_ax.flatten()[i].plot(np.linspace(0,(n_ts-1)*8000/86400,n_ts), \n",
    "                                   X_generated[:,[i,i+4], :, :].reshape(len(X_generated),-1).sum(axis=1), \n",
    "                                   'b-', \n",
    "                                   label='Priors')\n",
    "                    \n",
    "\n",
    "for i, group in enumerate(compartments):\n",
    "    if i in np.array(grid_points)[:,0]:\n",
    "        X_ax.flatten()[i].plot(np.array(obs_times)*8000/86400, \n",
    "                              X_obs[obs_times][:, [i,i+4], :, :].reshape(len(obs_times),-1).sum(axis=1), \n",
    "                              'ro', markevery=1, \n",
    "                              fillstyle='full', \n",
    "                              markersize = 10, \n",
    "                              label='Ground truth')\n",
    "#         X_ax.flatten()[i].errorbar(np.array(obs_times)*8000/86400, \n",
    "#                                    X_obs[obs_times][:, [i,i+4], :, :].reshape(len(obs_times),-1).sum(axis=1),\n",
    "#                                    yerr=3*0.05*X_obs[obs_times][:, [i,i+4], :, :].reshape(len(obs_times),-1).sum(axis=1),\n",
    "#                                    fmt='or',\n",
    "#                                    markersize = 6, \n",
    "#                                    elinewidth=3,\n",
    "#                                    #capsize = 10,\n",
    "#                                    #barsabove=True,\n",
    "#                                    zorder=3)\n",
    "\n",
    "        \n",
    "    X_ax.flatten()[i].set_title(group)\n",
    "    #X_ax.flatten()[i].legend()\n",
    "    X_ax.flatten()[i].set_xlabel('Time (days)')\n",
    "    X_ax.flatten()[i].set_ylabel('Number of People')\n",
    "    #X_ax.flatten()[0].set_ylim(top=8000)\n",
    "    \n",
    "X_mean = np.zeros((259, 8, 10, 10))\n",
    "for output_data in updated_output_data:\n",
    "    \n",
    "    X_generated = scaler.inverse_transform(output_data[1])\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    n_ts = len(X_generated)\n",
    "    X_mean += X_generated\n",
    "X_mean /= len(updated_output_data)  \n",
    "\n",
    "# Plot groups \n",
    "if len(X_ax): \n",
    "    for i, group in enumerate(compartments):\n",
    "        X_ax.flatten()[i].plot(np.linspace(0,(n_ts-1)*8000/86400,n_ts), \n",
    "                               X_mean[:,[i,i+4], :, :].reshape(len(X_generated),-1).sum(axis=1), \n",
    "                               'k-',  \n",
    "                               label='Posterior')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, X_ax = plt.subplots(1,4, figsize=[20,5])\n",
    "\n",
    "for output_data in list_output_data:\n",
    "    \n",
    "    X_generated = scaler.inverse_transform(output_data[0])\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    n_ts = len(X_generated)\n",
    "    \n",
    "    # Plot groups \n",
    "    if len(X_ax): \n",
    "        for i, group in enumerate(compartments):\n",
    "            X_ax.flatten()[i].plot(np.linspace(0,(n_ts-1)*8000/86400,n_ts), \n",
    "                                   X_generated[:,[i,i+4], :, :].reshape(len(X_generated),-1).sum(axis=1), \n",
    "                                   '-',\n",
    "                                   color='grey',\n",
    "                                   label='Priors')\n",
    "                    \n",
    "                \n",
    "for output_data in updated_output_data:\n",
    "    \n",
    "    X_generated = scaler.inverse_transform(output_data[1])\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    n_ts = len(X_generated)\n",
    "    \n",
    "    # Plot groups \n",
    "    if len(X_ax): \n",
    "        for i, group in enumerate(compartments):\n",
    "            X_ax.flatten()[i].plot(np.linspace(0,(n_ts-1)*8000/86400,n_ts), \n",
    "                                   X_generated[:,[i,i+4], :, :].reshape(len(X_generated),-1).sum(axis=1), \n",
    "                                   'b-', \n",
    "                                   label='Priors')                \n",
    "        \n",
    "for i, group in enumerate(compartments):\n",
    "    if i in np.array(grid_points)[:,0]:\n",
    "        X_ax.flatten()[i].plot(np.array(obs_times)*8000/86400, \n",
    "                              X_obs[obs_times][:, [i,i+4], :, :].reshape(len(obs_times),-1).sum(axis=1), \n",
    "                              'ro', markevery=1, \n",
    "                              fillstyle='full', \n",
    "                              markersize = 8, \n",
    "                              label='Ground truth')\n",
    "#         X_ax.flatten()[i].errorbar(np.array(obs_times)*8000/86400, \n",
    "#                                    X_obs[obs_times][:, [i,i+4], :, :].reshape(len(obs_times),-1).sum(axis=1),\n",
    "#                                    yerr=3*0.05*X_obs[obs_times][:, [i,i+4], :, :].reshape(len(obs_times),-1).sum(axis=1),\n",
    "#                                    fmt='or',\n",
    "#                                    markersize = 6, \n",
    "#                                    elinewidth=3,\n",
    "#                                    #capsize = 10,\n",
    "#                                    #barsabove=True,\n",
    "#                                    zorder=3)\n",
    "        \n",
    "    X_ax.flatten()[i].set_title(group)\n",
    "    #X_ax.flatten()[i].legend()\n",
    "    X_ax.flatten()[i].set_xlabel('Time (days)')\n",
    "    X_ax.flatten()[i].set_ylabel('Number of People')\n",
    "    #X_ax.flatten()[0].set_ylim(top=8000)\n",
    "    \n",
    "X_mean = np.zeros((259, 8, 10, 10))\n",
    "for output_data in updated_output_data:\n",
    "    \n",
    "    X_generated = scaler.inverse_transform(output_data[1])\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "    n_ts = len(X_generated)\n",
    "    X_mean += X_generated\n",
    "X_mean /= len(updated_output_data)  \n",
    "\n",
    "# Plot groups \n",
    "if len(X_ax): \n",
    "    for i, group in enumerate(compartments):\n",
    "        X_ax.flatten()[i].plot(np.linspace(0,(n_ts-1)*8000/86400,n_ts), \n",
    "                               X_mean[:,[i,i+4], :, :].reshape(len(X_generated),-1).sum(axis=1), \n",
    "                               'k-',  \n",
    "                               label='Posterior')    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 130\n",
    "X_hist_prior = []\n",
    "for output_data in list_output_data[:,0]: \n",
    "    X_generated = scaler.inverse_transform(output_data)\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "\n",
    "    X_hist_prior.append(X_generated[time,:, :, :].reshape(len(groups),-1).sum(axis=1))  \n",
    "X_hist_prior = np.array(X_hist_prior)\n",
    "\n",
    "X_hist_post = []\n",
    "for output_data in updated_output_data[:,1]: \n",
    "    X_generated = scaler.inverse_transform(output_data)\n",
    "    R0_generated = X_generated[:,pca_size:]\n",
    "    X_generated = pca_compress.inverse_transform(X_generated[:,:pca_size])\n",
    "    X_generated = X_generated.reshape(-1, len(groups), nl, nc)\n",
    "    X_generated[X_generated<0] = 0 \n",
    "\n",
    "    X_hist_post.append(X_generated[time,:, :, :].reshape(len(groups),-1).sum(axis=1))  \n",
    "X_hist_post = np.array(X_hist_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 16})\n",
    "mpl.rc('xtick', labelsize=22) \n",
    "mpl.rc('ytick', labelsize=22) \n",
    "mpl.rc('axes', labelsize=22)\n",
    "mpl.rc('axes', titlesize=22)\n",
    "\n",
    "fig, X_ax = plt.subplots(1,4, figsize=[20,5])\n",
    "# Plot groups histograms\n",
    "for i, group in enumerate(compartments):\n",
    "        #xrange = (X_hist[:,:4].min(),X_hist[:,:4].max()) if brange else None\n",
    "        X_ax.flatten()[i].hist(X_hist_prior[:,[i,i+4]].sum(axis=1), density=True, label='prior',alpha=0.7)\n",
    "        X_ax.flatten()[i].hist(X_hist_post[:,[i,i+4]].sum(axis=1), density=True, label='posterior',alpha=0.7)\n",
    "        X_ax.flatten()[i].set_xlabel('Number of people')\n",
    "        X_ax.flatten()[i].ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "\n",
    "        if i in np.array(grid_points)[:,0] and time in obs_times:\n",
    "            yrange = X_ax.flatten()[i].get_ybound()\n",
    "            X_ax.flatten()[i].plot([X_obs[time, [i,i+4], :, :].sum()]*2,yrange, linewidth=4, label='Ground truth')\n",
    "            X_ax.flatten()[i].set_ylim(yrange)      \n",
    "        X_ax.flatten()[i].set_title(group)\n",
    "        X_ax.flatten()[i].legend()     \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
